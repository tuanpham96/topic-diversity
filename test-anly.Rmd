---
title: "Topic/knowledge discovery and diversity in a social network"
subtitle: "A toy model idea"
author: Tuan Pham 
output:
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = ".", output_format = "all") })
---

```{r echo=F}
knitr::opts_chunk$set(
  echo = F, eval = T,  
  message=F, warning=F,
  fig.align = "center")
```

```{r include=F}
library(tidyverse)
library(reshape2)
library(purrr)

library(bipartite)
library(igraph)

library(pbmcapply)
library(ggpubr)

library(gtools)

library(microbiome)
library(moments)

source('src/topic_discovery.R')
source('src/topic_analysis.R')
```

```{r}
params_data <- readRDS('data/nonblock-models/params.rds')
params_df <- params_data$params
intra_generators <- params_data$intra_generators
inter_initiators <- params_data$inter_initiators

params_df %>% filter(
  p_alpha == 0.1,
  tau_max == 50,
  trial_id == 1,
  model_agent == 'ER_2' 
)
```


```{r}
test_file <- sprintf('data/nonblock-models/data-%06d.rds', 431)
test_file <- sprintf('data/block-models/data-%06d.rds', 431)
td <- readRDS(test_file)
info <- td$info
info
```

```{r}
G <- td$G
TAU_mat <- td$get_separate_matrices()$TAU
Matrix::image(TAU_mat,  
      useRaster = T)
 induced_subgraph(td$G,filter_noderole(V(td$G), 'topics')$name) %>% as_data_frame()
dim(TAU_mat)

# nestednodf(TAU_mat) 

# (as_adjacency_matrix(G, sparse = F) %>% eigen(only.values = T))$values %>% max

# as_adjacency_matrix(G, sparse = F) %>% melt %>% rename(topic=Var1, agent=Var2) %>% 
#   ggplot(aes(agent, topic, fill=value)) + geom_tile() + 
#   theme_pubclean()
```


```{r}
# `TAU [topic x agent]`, and `second.extinct` uses `web [lower x higher]` so remove `agent = higher` 
a <- second.extinct(TAU_mat, participant = 'higher', method = 'random', nrep = 10)
plot(a)
slope.bipartite(a)
robustness(a)
```

```{r}

nrep_2ndextinct <- 10 
calculate_entropy <- partial(vegan::diversity, index='shannon',  base = 2)

# get adjmat and distmat 
all_mats <- td$get_separate_matrices()
topic_distmat <- all_mats$T %>% 
  graph_from_adjacency_matrix(mode='undirected') %>% 
  distances(mode = 'all')
topic_distmat[is.infinite(topic_distmat)] <- NA # so don't consider Inf values 
  
# node data frames 
node_df <- as_data_frame(td$G, 'vertices')
topic_nodedf <- node_df %>% filter(role == 'topics') %>% 
  rename(topic_group = group) %>% 
  select(name,topic_group)
agent_nodedf <- node_df %>% filter(role == 'agents') %>% 
  rename(agent_group = group) %>%
  select(name,agent_group)

has_group <- !(topic_nodedf$topic_group[1] %>% is.na)

# learnt topics data frame
learnt_topics <- all_mats$TAU %>% melt %>% 
  filter(value > 0) %>%
  rename(topic=Var1, agent=Var2) %>%
  select(topic, agent) %>% 
  left_join(topic_nodedf, by = c("topic" = "name")) %>% 
  left_join(agent_nodedf, by = c("agent" = "name"))

summarized_by_topics <- learnt_topics %>% 
  select(topic, topic_group) %>% group_by(topic, topic_group) %>%
  summarise(count = length(topic))

# create lists
label_list <- list()
value_list <- list()

# number of topics 
label_list$N_T <- 'number of topics' 
value_list$N_T <- nrow(summarized_by_topics)

# topic population entropy 
label_list$H_p <- 'topic population entropy'
value_list$H_p <- calculate_entropy(summarized_by_topics$count)

# topic group population entropy
label_list$H_gp <- 'topic group population entropy'
value_list$H_gp <- NA

if (has_group) {
  summarized_by_topicgroups <- summarized_by_topics %>%
    group_by(topic_group) %>% 
    summarise(count = sum(count)) 
  value_list$H_gp <- calculate_entropy(summarized_by_topicgroups$count)
} 

# topic-agent group population joint entropy
label_list$H_gg <- 'topic-agent group population joint entropy'
value_list$H_gg <- NA

if (has_group) {
  topicgroup_agentgroup <- learnt_topics %>% 
    select(topic_group, agent_group) %>%
    group_by(topic_group, agent_group) %>% 
    summarise(count = n())
  value_list$H_gg <- calculate_entropy(topicgroup_agentgroup$count)
} 

# mean topic group individual entropy 
label_list$H_gi <- 'mean topic group individual-agent entropy'
value_list$H_gi <- NA

if (has_group) {
  peragent_topicgroupentropy <- learnt_topics %>% 
    group_by(agent, topic_group) %>%
    summarise(count = n()) %>% 
    group_by(agent) %>% 
    summarise(ent = calculate_entropy(count))
  
  value_list$H_gi <- mean(peragent_topicgroupentropy$ent)
} 

# evenness 
label_list$E_T <- 'topic Camargo evenness'
value_list$E_T <- microbiome::evenness(summarized_by_topics$count)$camargo

# rarity 
label_list$LMS_T <- 'topic log-modulo-skewness (rare index)'
value_list$LMS_T <- microbiome::log_modulo_skewness(summarized_by_topics$count)

# robustness 
# note: `TAU [topic x agent]`, and `second.extinct` uses `web [lower x higher]` so remove `agent = higher` 
#   random removal 
label_list$R_T_random <- 'topic robustness (random removal of agent)'
value_list$R_T_random <- all_mats$TAU %>% 
  bipartite::second.extinct(participant = 'higher', method = 'random', nrep = nrep_2ndextinct) %>% 
  bipartite::robustness()

#   targeted removal by degree
label_list$R_T_degree <- 'topic robustness (removal of agent by degree rank)'
value_list$R_T_degree <- all_mats$TAU %>% 
  bipartite::second.extinct(participant = 'higher', method = 'degree', nrep = nrep_2ndextinct) %>% 
  bipartite::robustness()

# subgraph statistics 
# d_g: mean distance of the distance matrix subsampled from the topic list
# d_s: mean distance of the induced subgraph from the topic list
# c_s_glob: global transitivity/clustering coefficient from induced subgraph 
# c_s_avr: average transitivity/clustering coefficient from induced subgraph 
# n_cc: number of connected component

substat_prefixes <- c(
  d_g = 'mean distance from subsampled topics',
  d_s = 'mean distance of the induced topic subgraph',
  c_s_glob = 'global clustering coefficient from induced topic subgraph',
  c_s_avr = 'average clustering coefficient from induced topic subgraph',
  n_cc = 'number of connected component of induced topic subgraph'
)

substat_suffixes <- c(
  mean = 'average', 
  med = 'median', 
  sd = 'standard deviation', 
  skew = 'skewness'
)

substat_namedesc <- expand_grid(prefix = names(substat_prefixes), 
                                suffix = names(substat_suffixes)) %>%
  mutate(label = sprintf('%s_%s', prefix, suffix), 
         description = sprintf('%s (%s)', substat_prefixes[prefix], substat_suffixes[suffix])) %>% 
  select(label, description) %>% 
  spread(label, description) %>% 
  as.list()

label_list <- c(label_list, substat_namedesc)

substats_values <-
  group_by(learnt_topics, agent) %>%
  summarise(
    d_g = mean(topic_distmat[topic, topic], na.rm = TRUE),
    d_s = induced_subgraph(td$G, topic) %>% mean_distance(directed=FALSE,unconnected=TRUE),   
    c_s_glob = induced_subgraph(td$G, topic) %>% transitivity(type='global'), 
    c_s_avr = induced_subgraph(td$G, topic) %>% transitivity(type='average'),
    n_cc = components(induced_subgraph(td$G, topic))$no
    ) %>%
  select(-agent) %>% 
  summarise_all(list(mean=mean,
                     med=median,
                     sd=sd,
                     skew=moments::skewness)) %>% 
  as.list()

value_list <- c(value_list, substats_values)

# Jaccard similarity list of topics between agents
label_list$Js_T <- 'mean pairwise Jaccard similarity of topics between agents'
Js_pw <- jacpop::generate_pw_jaccard(t(all_mats$TAU), n.pcs = NULL, plot_it = FALSE)$Jac
value_list$Js_T <- mean(Js_pw[upper.tri(Js_pw)], na.rm = TRUE)
```

```{r}
t0 <- Sys.time()
div_metric <- analyze_diversity(td)
Sys.time() - t0

```



```{r}
td <- readRDS(file.path(data_path, data_file))
df_edges <- as_data_frame(td$G)
time_vec <- seq(from=0,to=td$max_nsteps,by=samp_time)
topic_distmat <- induced_subgraph(td$G,filter_noderole(V(td$G), 'topics')$name) %>% distances(mode = 'all')

analysis_pertime <- lapply(time_vec, function(t_on) {
  df_edges_selected <- filter(df_edges, onset <= t_on & 
                                substr(from, start = 1, stop = 1) != substr(to, start = 1, stop = 1))
  
  summarized_by_topics <- select(df_edges_selected, to) %>% group_by(to) %>% summarise(count = length(to)) 
  topic_entropy <- calc_entropy(summarized_by_topics)
  num_topics <- nrow(summarized_by_topics)
  
  group_topic_entropy <- summarized_by_topics %>%
    left_join(topic_block_groups, by = c("to" = "topic_name")) %>%
    select(topic_group, count) %>%
    group_by(topic_group) %>%
    summarise(count = sum(count)) %>%
    calc_entropy
  
  summarized_by_agents <- group_by(df_edges_selected, from) %>% summarise(d=mean(topic_distmat[to,to]))
  sub_dist_mean <- mean(summarized_by_agents$d)
  sub_dist_median <- median(summarized_by_agents$d)
  
  return(tibble(t = t_on, topic_entropy, num_topics,
                group_topic_entropy, 
                sub_dist_mean, sub_dist_median))
}) %>% bind_rows
```

