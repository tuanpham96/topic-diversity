\section{Discussion}

In conclusion, with this simple toy model of topic discovery and a simple update rule depending on the probability of traversing through neighbors of bipartite networks, some interesting results are obtained. First of all, increasing in $\alpha$ (self-learning, traversing through interlayer edges first) leads to higher topic population diversity and robustness in various random models for the intralayer networks, including blocks and non-block models. However, such increase has drawbacks when looking at topic individual diversity, as it reduces the chance for the agent nodes to acquire interlayer edges from topics that are usually ``out-of-their-comfort-zone''. Traversing through intralayer edges first ($\beta$ route) would better benefit individual diversity.

When groups are considered in the intralayer networks, group modularity may hurt the population diversity (though some only by a little) and more apprently for group individual entropy, though interestingly more beneficial for individual indices through the lense of graph distances and components. Although initial group correspondence does not have much effects on the population diversity, it has a dramatic drawback at  the individual level (both entropy and graph metrics).

Though there are interesting results in a theoretical sense as a toy model, there are quite many limitations of the current model. Future studies should relax the assumptions made here and test out different versions of the models, for example inclusion of directed weighted edges (strengths could imply confidence in knowledge in $\tau$), non-persistent interlayer edges, different update probabilities (serendipity, forgetting, strengthing, ...), the cost of learning new subjects, delays in acquiring new knoweldge, different versions of the update equation. Furthermore, future endeavours should take into account performing the update process in real networks, which could be constructed using, as an example, the citation networks (agents as authors, papers as topics, groups as fields or subfields).

Additionally, even within the simulations already generated by this project, there are other directions for further explorations, including examination of the modularity changes in the bipartite $\tau$ or in the projected topic graphs (for example, low $\beta$ might start to create communities as evidenced by high Jaccard similarity), the distribution of specificialists and generalists, as well as calculation of nestedness (due to the defined maximum capacity $\tau_{\mathrm{max}}$, the density of the networks would already be controlled). Furthermore, due to the assumption of persistent interlayer edges, it is possible to characterize properties of persistent homlogy of the networks (or the projected version).

In a bigger picture, regardless of questions about information or diversity, how might the process laid out by this model be relevant to other systems? Due to the simplicity set out by the model and the update process, there could be some biological interpretations, though quite loosely and to be taken lightly. For example, in an ecological perspective, one could consider the agent graph as species with links as certain phenotypic/genotypic similarity, and the topic graph as the different environments with links as environmental similarity. The interlayer edges would represent adaptation of a given species to a given environment. The $\alpha$ route would, in a sense, be analogous to adaptation to new environments that share certain similarity with already-adaptated environments. On the other hand, the $\beta$ route could be adaptation to a new environment that the animal has never been in, yet in nature there already exists similar species that has adaptated to such environment, hence such new adaptation is probable.

Another example can be from the neuroscience perspective, albeit in an oversimplified fashion and possibly biologically implausible. However, as a thought model, the agent graph could be neurons with links between them as correlations between them (either structurally via synaptic connections or functionally through activity). The topic graph could be inputs, in which the intralayer edges could represent either coincidence between these different types of inputs or similarity between them. The interlayer edges could represent which inputs a given neuron could code for. The update process shares some inspiration from associative learning. The $\alpha$ route may represent neurons acquire new inputs to code for due to co-occurence of inputs or just because the inputs are sufficiently similar. The $\beta$ route could be because the neuron gets recruited into the engram encoded for a certain object or abstract concept due to the correlative activity with another neuron that already codes for such object.
